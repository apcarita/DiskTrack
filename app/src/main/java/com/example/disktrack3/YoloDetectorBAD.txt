   implementation 'com.google.android.gms:play-services-tflite-java:16.1.0'
    implementation 'com.google.android.gms:play-services-tflite-support:16.1.0'
    implementation 'com.google.android.gms:play-services-tflite-gpu:16.2.0'


    // LiteRT dependencies for Google Play services - Use specific doc versions
  //  implementation 'com.google.android.gms:play-services-tflite-java:16.1.0' // Base Java API (as per doc step 1)
    //implementation 'com.google.android.gms:play-services-tflite-support:16.1.0'

    //implementation 'com.google.android.gms:play-services-tflite-gpu:16.2.0'  // GPU Delegate support (as per doc GPU section)

    // Optional: include LiteRT Support Library (Uncomment if needed later, ensure version matches)
    // implementation 'com.google.android.gms:play-services-tflite-support:16.1.0' // Match java version if used



package com.example.disktrack3

import android.content.Context
import android.content.res.AssetManager
import android.graphics.Bitmap
import android.util.Log
import org.opencv.android.Utils
import org.opencv.core.Mat
import org.opencv.core.MatOfFloat
import org.opencv.core.MatOfInt
import org.opencv.core.MatOfRect2d
import org.opencv.core.Rect
import org.opencv.core.Rect2d
import org.opencv.core.Size
import org.opencv.dnn.Dnn
import org.opencv.imgproc.Imgproc
import org.tensorflow.lite.DataType
import org.tensorflow.lite.InterpreterApi

import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel
import java.util.Locale
import java.util.concurrent.atomic.AtomicBoolean
import kotlin.math.max
import kotlin.math.min

class YoloDetector(
    context: Context,
    options: InterpreterApi.Options
) {

    private val TAG = "YoloDetector_CPU"
    private val TFLITE_MODEL_FILE = "yolo11n.tflite"
    private val YOLO_INPUT_SIZE = 640
    private val YOLO_CONFIDENCE_THRESHOLD = 0.25f
    private val YOLO_IOU_THRESHOLD = 0.45f

    private var tfliteInterpreter: InterpreterApi? = null
    private val isInitialized = AtomicBoolean(false)
    private var inputByteBuffer: ByteBuffer? = null
    private var outputBuffer: Array<Array<FloatArray>>? = null
    var classNames: List<String> = listOf()

    private val cocoLabels = listOf(
        "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
        "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
        "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
        "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball",
        "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket",
        "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
        "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair",
        "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse",
        "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator",
        "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"
    )
    private val ACTUAL_EXPECTED_NUM_CLASSES = 80
    private val OUTPUT_NUM_PARAMS = 84
    private val OUTPUT_NUM_PREDICTIONS = 8400

    init {
        try {
            Log.w(TAG, "INIT: Starting YoloDetector (CPU) initialization...")
            val assetManager = context.assets
            Log.i(TAG, "INIT: Loading model file: $TFLITE_MODEL_FILE")
            val modelBuffer = loadModelFile(assetManager, TFLITE_MODEL_FILE)
            Log.i(TAG, "INIT: Model file loaded.")

            Log.w(TAG, "INIT: Creating TFLite InterpreterApi with provided options...")
            tfliteInterpreter = InterpreterApi.create(modelBuffer, options)
            Log.w(TAG, "INIT: TFLite InterpreterApi created.")

            val bufferSize = 1 * YOLO_INPUT_SIZE * YOLO_INPUT_SIZE * 3 * 4
            Log.i(TAG, "INIT: Allocating input buffer size: $bufferSize bytes")
            inputByteBuffer = ByteBuffer.allocateDirect(bufferSize)
            inputByteBuffer?.order(ByteOrder.nativeOrder())
            Log.i(TAG, "INIT: Input buffer allocated.")

            val outputTensor = tfliteInterpreter?.getOutputTensor(0)
            val reportedOutputShape = outputTensor?.shape() ?: intArrayOf(0, 0, 0)
            val outputDataType = outputTensor?.dataType() ?: DataType.FLOAT32
            Log.i(TAG, "INIT: Output Shape: ${reportedOutputShape.joinToString()}, DataType: $outputDataType")

            val BATCH_SIZE = 1
            Log.i(TAG, "INIT: Allocating output buffer...")
            outputBuffer = Array(BATCH_SIZE) { Array(OUTPUT_NUM_PARAMS) { FloatArray(OUTPUT_NUM_PREDICTIONS) } }
            Log.i(TAG, "INIT: Output buffer allocated.")

            val NUM_PARAMS = OUTPUT_NUM_PARAMS
            val NUM_CLASSES = NUM_PARAMS - 4
            Log.i(TAG, "INIT: Using Num Classes: $NUM_CLASSES")
            if (NUM_CLASSES != ACTUAL_EXPECTED_NUM_CLASSES) {
                Log.e(TAG, "FIXED class count ($NUM_CLASSES) does not match expected COCO count ($ACTUAL_EXPECTED_NUM_CLASSES). Check NUM_PARAMS.")
            }
            if (cocoLabels.size != ACTUAL_EXPECTED_NUM_CLASSES) {
                Log.w(TAG, "Mismatch between cocoLabels size (${cocoLabels.size}) and ACTUAL_EXPECTED_NUM_CLASSES ($ACTUAL_EXPECTED_NUM_CLASSES).")
            }

            classNames = cocoLabels

            Log.w(TAG, "INIT: About to set isInitialized to true.")
            isInitialized.set(true)
            Log.w(TAG, "INIT: YoloDetector (CPU) initialized SUCCESSFULLY.")
        } catch (e: Exception) {
            Log.e(TAG, "Error initializing YoloDetector (CPU): ${e.message}", e)
            isInitialized.set(false)
            tfliteInterpreter?.close()
            tfliteInterpreter = null
        }
    }

    fun isReady(): Boolean = isInitialized.get()

    @Throws(Exception::class)
    private fun loadModelFile(assetManager: AssetManager, modelPath: String): MappedByteBuffer {
        val fileDescriptor = assetManager.openFd(modelPath)
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = inputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
    }

    data class Detection(val boundingBox: Rect, val confidence: Float, val classIndex: Int, val className: String)

    fun detect(bitmap: Bitmap, frameWidth: Int, frameHeight: Int): List<Detection> {
        if (!isInitialized.get() || tfliteInterpreter == null || inputByteBuffer == null || outputBuffer == null) {
            Log.w(TAG, "Detector not initialized or buffers are null.")
            return emptyList()
        }

        val resizedBitmap = Bitmap.createScaledBitmap(bitmap, YOLO_INPUT_SIZE, YOLO_INPUT_SIZE, true)

        inputByteBuffer?.rewind()
        val intValues = IntArray(YOLO_INPUT_SIZE * YOLO_INPUT_SIZE)
        resizedBitmap.getPixels(intValues, 0, resizedBitmap.width, 0, 0, resizedBitmap.width, resizedBitmap.height)

        var pixel = 0
        for (i in 0 until YOLO_INPUT_SIZE) {
            for (j in 0 until YOLO_INPUT_SIZE) {
                val value = intValues[pixel++]
                val r = ((value shr 16 and 0xFF) / 255.0f)
                val g = ((value shr 8 and 0xFF) / 255.0f)
                val b = ((value and 0xFF) / 255.0f)
                inputByteBuffer?.putFloat(r)
                inputByteBuffer?.putFloat(g)
                inputByteBuffer?.putFloat(b)
            }
        }

        try {
            tfliteInterpreter?.run(inputByteBuffer, outputBuffer)
        } catch (e: Exception) {
            Log.e(TAG, "TFLite inference error: ${e.message}", e)
            return emptyList()
        }

        val allDetections = processOutput(outputBuffer!!, frameWidth, frameHeight)
        val personDetections = allDetections.filter { it.className.equals("person", ignoreCase = true) }
        return personDetections
    }

    private fun processOutput(output: Array<Array<FloatArray>>, frameWidth: Int, frameHeight: Int): List<Detection> {
        val NUM_PREDICTIONS = OUTPUT_NUM_PREDICTIONS
        val NUM_PARAMS = OUTPUT_NUM_PARAMS
        val NUM_CLASSES = NUM_PARAMS - 4

        val detections = mutableListOf<Detection>()
        val boundingBoxes = mutableListOf<Rect2d>()
        val confidences = mutableListOf<Float>()
        val classIndexes = mutableListOf<Int>()

        for (i in 0 until NUM_PREDICTIONS) {
            val centerX = output[0][0][i]
            val centerY = output[0][1][i]
            val width = output[0][2][i]
            val height = output[0][3][i]

            var maxClassScore = 0f
            var classIndex = -1
            for (j in 0 until NUM_CLASSES) {
                val classScore = output[0][4 + j][i]
                if (classScore > maxClassScore) {
                    maxClassScore = classScore
                    classIndex = j
                }
            }

            if (maxClassScore >= YOLO_CONFIDENCE_THRESHOLD) {
                if (classIndex != -1) {
                    val scaleX = frameWidth.toDouble() / YOLO_INPUT_SIZE
                    val scaleY = frameHeight.toDouble() / YOLO_INPUT_SIZE

                    val scaledCenterX = centerX * scaleX
                    val scaledCenterY = centerY * scaleY
                    val scaledWidth = width * scaleX
                    val scaledHeight = height * scaleY

                    val x1 = max(0.0, (scaledCenterX - scaledWidth / 2.0))
                    val y1 = max(0.0, (scaledCenterY - scaledHeight / 2.0))
                    val x2 = min(frameWidth.toDouble() - 1, (scaledCenterX + scaledWidth / 2.0))
                    val y2 = min(frameHeight.toDouble() - 1, (scaledCenterY + scaledHeight / 2.0))

                    val rectWidth = max(0.0, x2 - x1)
                    val rectHeight = max(0.0, y2 - y1)

                    if (rectWidth > 0 && rectHeight > 0) {
                        boundingBoxes.add(Rect2d(x1, y1, rectWidth, rectHeight))
                        confidences.add(maxClassScore)
                        classIndexes.add(classIndex)
                    }
                }
            }
        }

        if (boundingBoxes.isEmpty()) {
            return emptyList()
        }

        val boxesMat = MatOfRect2d(*boundingBoxes.toTypedArray())
        val confidencesMat = MatOfFloat(*confidences.toFloatArray())
        val indicesMat = MatOfInt()

        try {
            Dnn.NMSBoxes(boxesMat, confidencesMat, YOLO_CONFIDENCE_THRESHOLD, YOLO_IOU_THRESHOLD, indicesMat)
        } catch (e: Exception) {
            Log.e(TAG, "NMSBoxes Error: ${e.message}. Check OpenCV version and DNN module.")
            boxesMat.release()
            confidencesMat.release()
            indicesMat.release()
            return emptyList()
        }

        val keepIndices = indicesMat.toArray()
        for (index in keepIndices) {
            if (index < 0 || index >= boundingBoxes.size) {
                continue
            }
            val rect = boundingBoxes[index]
            val classIdx = classIndexes[index]
            val className = if (classIdx >= 0 && classIdx < classNames.size) {
                classNames[classIdx]
            } else {
                "Unknown ($classIdx)"
            }

            val detection = Detection(
                Rect(rect.x.toInt(), rect.y.toInt(), rect.width.toInt(), rect.height.toInt()),
                confidences[index],
                classIdx,
                className
            )
            detections.add(detection)
        }

        boxesMat.release()
        confidencesMat.release()
        indicesMat.release()

        return detections
    }

    fun close() {
        Log.d(TAG, "Closing YoloDetector (CPU)...")
        tfliteInterpreter?.close()
        tfliteInterpreter = null
        isInitialized.set(false)
        Log.d(TAG, "YoloDetector (CPU) closed.")
    }
}
